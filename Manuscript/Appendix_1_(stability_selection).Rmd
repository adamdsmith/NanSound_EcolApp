---
header-includes:
  - \usepackage{lscape}
  - \newcommand{\blscape}{\begin{landscape}}
  - \newcommand{\elscape}{\end{landscape}}
output: 
  pdf_document:
fontsize: 12pt
geometry: margin=1in
number_sections: true
documentclass: article
bibliography: NantucketMS.bib
csl: ecology.csl
---
```{r occ_stabsel_results, echo=FALSE, message=FALSE, warning=FALSE}
require(gamboostLSS)
load("../Results_coei/stabs_zero_q35.Rda")
stabs_zero_q35 <- stabsel(stabs_zero_q35, PFER = 2, assumption = "unimodal")
coei_stabs_zero <- stabs_zero_q35

load("../Results_scot/stabs_zero_q35.Rda")
stabs_zero_q35 <- stabsel(stabs_zero_q35, PFER = 2, assumption = "unimodal")
scot_stabs_zero <- stabs_zero_q35

load("../Results_ltdu/stabs_zero_q35.Rda")
stabs_zero_q35 <- stabsel(stabs_zero_q35, PFER = 2, assumption = "unimodal")
ltdu_stabs_zero <- stabs_zero_q35
```

```{r count_stabsel_results, echo=FALSE}
load("../Results_coei/stabs_hurdle_q35.Rda")
stabs_hurdle_q35 <- stabsel(stabs_hurdle_q35, PFER = 2, assumption = "r-concave")
coei_stabs_hurdle <- stabs_hurdle_q35

load("../Results_scot/stabs_hurdle_q35.Rda")
stabs_hurdle_q35 <- stabsel(stabs_hurdle_q35, PFER = 2, assumption = "r-concave")
scot_stabs_hurdle <- stabs_hurdle_q35

load("../Results_ltdu/stabs_hurdle_q35.Rda")
stabs_hurdle_q35 <- stabsel(stabs_hurdle_q35, PFER = 2, assumption = "r-concave")
ltdu_stabs_hurdle <- stabs_hurdle_q35
```

# Appendix 1. Stability selection

## Methods

We applied stability selection [@Meinshausen2010; @Shah2013] to identify base-learners, and thus covariates, that were commonly selected in the majority of ~~100~~ random**_ly drawn_** subsamples **_of size $\lfloor n/2 \rfloor$_** of the data. **_As proposed by @Shah2013, we used $B = 50$ complementary pairs subsamples, i.e., we randomly split the data into two halves and used both to independently fit the model. This led to 100 subsamples all together._** We set the number of selected base-learners per boosting model (*q*) to 35 and established an upper bound of two for the per-family error rate [PFER; @Meinshausen2010; @Shah2013; see also @Hofner2015a for details in the context of boosting] ~  ~which, given the 48 base-learners in the occupancy and count models (see Equation 1 in manuscript),~~**_. This error bound_** corresponded to an upper bound of $\alpha$ = `r round(2/48, 3)` for the per-comparison error rate **_in the occupancy model and an upper bound of $\alpha$ = `r round(2/96, 3)` in the count model_**. **_The choice of $q$ is rather arbitrary as long as it is large enough to incorporate all important variables in the model [@Hofner2015a]. We used the unimodality assumption for the compuation of the error bounds in the occupancy model and, to be less conservative, we used the r-concavity assumption in the count model [@Shah2013; @Hofner2015a]._** 

**~~Benjamin: can you check my calculation?  Also, should we explain why we chose *q* = 35, or describe complementary pairs subsampling and our choice of unimodal vs. r-concavity assumptions for the two model type (occupancy vs. count)?  Any other relevant details to include?~~**

**_BH: As you can see from the different thresholds we have a different number of base-learners in the two models. The occupancy model really has 48 base-learners but the count model has twice as many, i.e., 96 base-learners, 48 for the mean and 48 for the dispersion parameter. Furthermore, if you print any of the stabsel objects, you will find the (realized) PCER given as 0.0208 (= 1/48) for the occupancy model and 0.0188 (= 1.8 / 96) for the count model._**

**_BH: I need to check here why the upper bound for the PFER is specified as 2 but the PFER is then given as 1._**

**_BH: We could (and should) state the further assumptions (unimodality and r-concavity). Do you remember the reason why we use different assumptions for the two models? I added a sentence. Is this correct and do we want to keep it? Perhaps it raises more questions than it answers._**

## Results

### Occupancy models

Given our specifications (*q* = 35; PFER upper-bound = 2, **_unimodality assumption_**), only base-learners selected in all 100 subsamples (i.e., $\hat{\pi}$ = 1) were identified as stable (Figure 1.1).

### Count models
Given our specifications (*q* = 35; PFER upper-bound = 2, **_r-concavity assumption_**), only base-learners selected in at least 90 of the 100 subsamples (i.e., $\hat{\pi}$ = 0.9) were identified as stable; this threshold applies to the selection of base-learners for the conditional mean ($\mu$) and conditional overdispersion ($\sigma$) **_simultaniously_**.
\newpage
\blscape
```{r occ_stabsel_plot, echo=FALSE, eval=FALSE}
# Figure 1.1 was created using the following script, although for nice formatting
# (and time considerations) we simply link to the final PNG file, below
source("../R/stability_selection_occupancy_plot.R")
```
![Occupancy stability selection](./Figures/stability_selection_occupancy.png)  
**Figure 1.1** Stability selection using complementary pairs subsampling and unimodality assumption for sea duck occupancy models. The number of selected base-learners in each model run was set to *q* = 35.  Base-learners with selection frequencies above the threshold ($\hat{\pi}$; vertical gray line) were considered stable with upper bound PFER = 2.   

\newpage
```{r count_stabsel_plot, echo=FALSE, eval=FALSE}
# Figures 1.2 and 1.3 were created using the following script, although for nice formatting
# (and time considerations) we simply link to the final PNG file, below
source("../R/stability_selection_count_plot.R")
```
![Count stability selection](./Figures/stability_selection_count.png)  
**Figure 1.2** Stability selection using complementary pairs subsampling and r-concavity assumption for sea duck conditional count models. The number of selected base-learners in each model run was set to *q* = 35.  Base-learners with selection frequencies above the threshold ($\hat{\pi}$; vertical gray line) were considered stable with upper bound PFER = 2.  Only the top 48 base-learners are illustrated. Brackets indicate the parameter (conditional mean, *mu*, or overdispersion, *sigma*) to which the base-learner applies.

\elscape

## Literature cited
